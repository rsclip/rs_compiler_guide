# Introduction
This guide serves as a brief process of developing a compiler for our own programming language from scratch into executable programs. We'll cover each stage of compilation, from tokenization to code generation, all with explanations.

I am quite a beginner in both Rust and Compiler Development, so the code may be messy and very badly/inefficiently implemented. Either way, it can be a great starting point!

Not all code covered will be included in the guide, but the final code will be available in the final GitHub repository at the bottom.
## Goals of the Guide
Learning how to develop a compiler is ridiculously confusing with a high barrier-to-entry and no solid guide on how to make one. Thus, this guide will:
- Provide a somewhat thorough understanding of the compilation process, including its stages and components
- Explains the role and significance of each stage of said process
- Offer insights into common techniques, optimizations, etc. used in modern compilers
- Provide a good understanding in how languages actually work
- Allow you to make your own compiler! Kind of.
## Prerequisites
While this guide aims to be accessible to developers at various levels, you should have an intermediate understanding of programming languages and Computer Science fundamentals.

The guide uses Rust exclusively, but it avoids difficult or non-conventional concepts. It can be followed in another similar language to an extent.

**Recommended:**
- Good understanding of programming concepts (variables, data-types, control structures, functions, recursive & iterative methods, etc.)
- Familiarity with Rust (if you know C++, this should be relatively easy to pick up)
- Understanding of fundamental data structures (stacks, trees, etc.)
- Knowledge of algorithm design & analysis principles

**Beneficial**:
Albeit not required, it would greatly help if you have knowledge of some more topics.
- Understanding of memory management concepts
- Knowledge of Abstract Syntax Trees (ASTs)
- Understanding of grammars (EBNF, BNF, etc.)
- Knowledge of basic compiler theory concepts (lexical analysis, parsing, optimization, etc.)
- Familiarity with any Assembly languages or low-level programming concepts

A lot of these will be covered regardless.
## Overview of Compilers
### What is a Compiler?
A compiler is a program that translates source code (represented as text) written in a higher-level programming language into machine code which a computer can execute directly. It may also be translated into bytecode, in which a virtual machine (like Java's Virtual Machine or Python's interpreter) can interpret and run, although this requires the VM to be installed. It plays a crucial role by facilitating in the conversion of human-readable code into a format understandable by the computer's hardware.

### Key concepts
There are some critical concepts of Compiler Theory you need to understand before going through the stages:

**Abstract Syntax Trees**: ASTs are trees which determine the structure of the program in a machine-readable way. For example, `a = 1 + 2` becomes:

```
	VarDeclaration
Ident(a)       Add
			1		2
```

**Tokens**: Represent the small "building blocks" of text, as opposed to a list of characters. For example, `fn main() { return 0; }` would be `["fn", "main", "(", ")", "{", "return", "0", ";", "}"`. There are no whitespaces.

**Instruction Set Architecture**: ISAs are a set of instructions a processor can run on. These vary from architecture to architecture.

**Intermediate Representation**: Different devices have different ISAs, and so the last code we generate will be an intermediate representation between ASTs and actual Assembly code. This way, we can convert it to multiple ISAs much more easily.
### Components of a Compiler
There's various components of a Compiler which the source code has to go through:

**Lexer (Tokenizer)**:
Breaks down the source code into smaller units called **tokens**. These represent the smallest meaningful elements of the programming language such as keywords, identifiers, and literals. We use this to ignore redundant characters like whitespaces, making it easier for us to parse.

This would also allow us to identify when there are unexpected characters or unterminated strings, for example.

**Parser**:
The parser analyzes the structure of the source code by parsing the stream of tokens generated by the lexer. It verifies whether the code conforms to the grammar rules of the language, generating an Abstract Syntax Tree (AST).

**Semantic Analyzer**:
Performs analysis to check for type compatibility, variable declarations, scoping rules, and more to ensure the code behaves as intended. This is especially important if the user does not return the correct type, which -- if gone unchecked -- can be especially catastrophic and unsafe; imagine a function intended to return a pointer to dynamically allocated memory (like a Vector), but due to a type-checking error, it instead returns a pointer to a different object. The caller may not properly deallocate memory (leading to memory leaks), and subsequent operations on the data could lead to memory corruption.

**IR generation**:
From the resulting AST, the compiler generates an Intermediate Representation (IR) code prior to translating to Assembly. This is especially important since different computers, devices, and operating systems run on different architectures and ISAs (Instruction Set Architecture). This would be the lowest level of code yet produced, and we can easily convert this to assembly depending on the ISA.

**Optimization**:
Applies various transformations to the IR -- or directly to the AST -- to improve the efficiency and performance of the generated code. They may include constant folding (converting `3 + 2` into just `5`), loop unrolling (getting rid of the condition checks), dead code elimination (removing parts that are never used), and register allocation (assigning variables/values to processor registers instead of memory locations, as they are significantly faster).

**Code generation**:
Finally, the optimized IR is translated into machine code suitable for execution on the target ISA. This maps the constructs in IR to low-level instructions, whilst ensuring the target architecture's resources are being used efficiently.